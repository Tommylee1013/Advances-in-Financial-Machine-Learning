{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import FinancialMachineLearning as fml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-12T01:40:21.450626Z",
     "end_time": "2023-05-12T01:40:22.609218Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chapter 7. Cross-Validation in Finance\n",
    "\n",
    "#### Exercise 1\n",
    "\n",
    "금융에 있어서 K-Fold Cross Validation을 수행하기 전에 데이터셋을 섞는 것이 일반적으로 좋지 않은 이유는 무엇인가?데이터를 Shuffling하는 목적은 무엇인가? 데이터를 Shuffling하면 금융 데이터셋에 있어 K-Fold Cross Validation의 목적이 무의미해지는 이유는 무엇인가?\n",
    "\n",
    "답 : 우리가 사용하는 금융 시계열 데이터셋인데, 만약 데이터셋을 섞게 된다면 순차적 시간 정보다 뒤섞이게 된다. 이는 오히려 추정기의 성능을 떨어뜨리는 결과를 낳게 된다. 일반적으로 Data Science 분야에서 교차 검증을 위해 데이터를 섞는 이유는 무작위 표본 추출로 test, validation, train set을 선택하기 위함인데, 금융 시계열 데이터에서는 Shuffling을 한다면 시간 정보가 사라지고, information leak 등의 다양한 문제가 발생하게 되어 결과적으로 목적이 무의미해진다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 2\n",
    "\n",
    "관측된 특성과 레이블로 구성된 한 쌍의 행렬$(X,y)$을 하나 구하자. 3장 연습 문제에서 도출한 데이터셋 중 하나를 사용해도 된다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-12T01:40:22.610075Z",
     "end_time": "2023-05-12T01:40:22.627710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               Unnamed: 0    dollar  frac_diff_dollar        tW         w  bin\n0     2009-11-04 14:41:43   50.4500          0.529761  0.750000  1.984399 -1.0\n1     2009-11-04 15:43:57   49.8800         -0.137134  0.444444  0.077423  1.0\n2     2009-11-05 09:46:35   50.2080          0.349295  0.388889  3.523273  1.0\n3     2009-11-06 10:39:27   50.5448          0.038635  0.333333  3.626638  1.0\n4     2009-11-06 12:37:18   50.9232          0.559177  0.333333  2.644159  1.0\n...                   ...       ...               ...       ...       ...  ...\n3467  2018-09-26 10:07:41  116.5780          0.334817  0.209694  0.813016 -1.0\n3468  2018-09-26 15:47:29  115.9960          0.220088  0.189087  0.495700  1.0\n3469  2018-09-27 10:02:15  116.1100          0.750801  0.176905  0.055908 -1.0\n3470  2018-09-27 15:39:35  115.9000          0.349971  0.166905  0.621259  1.0\n3471  2018-09-28 10:35:39  115.9530          0.746292  0.166905  0.122451  1.0\n\n[3472 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>dollar</th>\n      <th>frac_diff_dollar</th>\n      <th>tW</th>\n      <th>w</th>\n      <th>bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2009-11-04 14:41:43</td>\n      <td>50.4500</td>\n      <td>0.529761</td>\n      <td>0.750000</td>\n      <td>1.984399</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2009-11-04 15:43:57</td>\n      <td>49.8800</td>\n      <td>-0.137134</td>\n      <td>0.444444</td>\n      <td>0.077423</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2009-11-05 09:46:35</td>\n      <td>50.2080</td>\n      <td>0.349295</td>\n      <td>0.388889</td>\n      <td>3.523273</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009-11-06 10:39:27</td>\n      <td>50.5448</td>\n      <td>0.038635</td>\n      <td>0.333333</td>\n      <td>3.626638</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009-11-06 12:37:18</td>\n      <td>50.9232</td>\n      <td>0.559177</td>\n      <td>0.333333</td>\n      <td>2.644159</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3467</th>\n      <td>2018-09-26 10:07:41</td>\n      <td>116.5780</td>\n      <td>0.334817</td>\n      <td>0.209694</td>\n      <td>0.813016</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>3468</th>\n      <td>2018-09-26 15:47:29</td>\n      <td>115.9960</td>\n      <td>0.220088</td>\n      <td>0.189087</td>\n      <td>0.495700</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3469</th>\n      <td>2018-09-27 10:02:15</td>\n      <td>116.1100</td>\n      <td>0.750801</td>\n      <td>0.176905</td>\n      <td>0.055908</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>3470</th>\n      <td>2018-09-27 15:39:35</td>\n      <td>115.9000</td>\n      <td>0.349971</td>\n      <td>0.166905</td>\n      <td>0.621259</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3471</th>\n      <td>2018-09-28 10:35:39</td>\n      <td>115.9530</td>\n      <td>0.746292</td>\n      <td>0.166905</td>\n      <td>0.122451</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3472 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sp500featureBin.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1].values # dollar, frac_diff, tW, w\n",
    "y = df.iloc[:,-1].values.reshape(-1,1) # bin"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-12T01:40:22.631372Z",
     "end_time": "2023-05-12T01:40:22.646144Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, BaggingClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle = False, random_state = 42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-12T01:40:22.636273Z",
     "end_time": "2023-05-12T01:40:22.646535Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(a)** $(X,y)$에 대해 데이터를 Shuffling하지 않고 Random Forest Classifier의 10 Fold Cross Validation의 성능을 도출해 보라"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "classes = np.unique(y_train.reshape(1,-1))\n",
    "weights = compute_class_weight(class_weight = 'balanced', classes = classes, y = y_train.reshape(-1,))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-12T01:40:22.640929Z",
     "end_time": "2023-05-12T01:40:22.669161Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "      class_weight\n0         0.888158\n1         1.144068\n2         1.144068\n3         1.144068\n4         1.144068\n...            ...\n3467      0.888158\n3468      1.144068\n3469      0.888158\n3470      1.144068\n3471      1.144068\n\n[3472 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class_weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.888158</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.144068</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.144068</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.144068</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.144068</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3467</th>\n      <td>0.888158</td>\n    </tr>\n    <tr>\n      <th>3468</th>\n      <td>1.144068</td>\n    </tr>\n    <tr>\n      <th>3469</th>\n      <td>0.888158</td>\n    </tr>\n    <tr>\n      <th>3470</th>\n      <td>1.144068</td>\n    </tr>\n    <tr>\n      <th>3471</th>\n      <td>1.144068</td>\n    </tr>\n  </tbody>\n</table>\n<p>3472 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cweight = pd.DataFrame()\n",
    "cweight.index = df.index\n",
    "cweight['class_weight'] = np.nan\n",
    "cweight.loc[df[df.bin == -1.0].index] = weights[1]\n",
    "cweight.loc[df[df.bin == 1.0].index] = weights[0]\n",
    "cweight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-12T01:40:22.648852Z",
     "end_time": "2023-05-12T01:40:22.705894Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_clf Mean CV score: -0.717943\n",
      "CV Variance: 0.006818\n"
     ]
    }
   ],
   "source": [
    "#based on book recommendation\n",
    "rf = RandomForestClassifier(n_estimators = 1000, criterion = \"entropy\", bootstrap = True,\n",
    "                                n_jobs=1, random_state=42, class_weight = 'balanced_subsample', oob_score=False)\n",
    "cv_gen = KFold(n_splits = 10, shuffle = False)\n",
    "score = fml.cvScore(rf, X, y, sample_weight = cweight, scoring = 'neg_log_loss', cv = None, cvGen = cv_gen, pctEmbargo = 0)\n",
    "print('rf_clf Mean CV score: {0:.6f}\\nCV Variance: {1:.6f}'.format(score.mean(), score.var()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-12T01:40:22.659687Z",
     "end_time": "2023-05-12T01:41:44.024034Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(b)** $(X,y)$에 대해 데이터를 섞으며 Random Forest Classifier의 10 Fold Cross Validation의 검증 성능을 도출해 보라"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_clf Mean CV score: -0.556278\n",
      "CV Variance: 0.000234\n"
     ]
    }
   ],
   "source": [
    "cv_gen0 = KFold(n_splits = 10, random_state = 42, shuffle = True)\n",
    "\n",
    "score = fml.cvScore(rf, X, y, sample_weight = cweight, scoring = 'neg_log_loss', cv = None, cvGen = cv_gen0, pctEmbargo = 0)\n",
    "print('rf_clf Mean CV score: {0:.6f}\\nCV Variance: {1:.6f}'.format(score.mean(), score.var()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-12T01:45:09.154962Z",
     "end_time": "2023-05-12T01:46:34.377751Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(c)** 두 결과가 많이 다른 이유는 무엇인가?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(d)** 데이터를 Shuffling하면 Information Leak이 어떻게 일어나는가?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 3\n",
    "Exercise 2에서 사용한 것과 동일한 $(X,y)$행렬을 사용하자\n",
    "\n",
    "**(a)** $(X,y)$에 대해 1% Embargo를 사용한 Random Forest Classifier의 10 Fold Purged Cross Validation의 검증 성능을 도출해 보라"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Label Through Dates must be a pd.Series",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m rf \u001B[38;5;241m=\u001B[39m RandomForestClassifier(n_estimators \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1000\u001B[39m, criterion \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mentropy\u001B[39m\u001B[38;5;124m\"\u001B[39m, bootstrap \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m      2\u001B[0m                                 n_jobs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m, random_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m42\u001B[39m, class_weight \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbalanced_subsample\u001B[39m\u001B[38;5;124m'\u001B[39m, oob_score \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m----> 3\u001B[0m score \u001B[38;5;241m=\u001B[39m \u001B[43mfml\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcvScore\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mcweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mneg_log_loss\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpctEmbargo\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrf_clf Mean CV score: \u001B[39m\u001B[38;5;132;01m{0:.6f}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mCV Variance: \u001B[39m\u001B[38;5;132;01m{1:.6f}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(score\u001B[38;5;241m.\u001B[39mmean(), score\u001B[38;5;241m.\u001B[39mvar()))\n",
      "File \u001B[0;32m~/Desktop/Pycharm/Financial_Machine_Learning/FinancialMachineLearning.py:1303\u001B[0m, in \u001B[0;36mcvScore\u001B[0;34m(clf, X, y, sample_weight, scoring, t1, cv, cvGen, pctEmbargo)\u001B[0m\n\u001B[1;32m   1300\u001B[0m \u001B[38;5;66;03m#   from clfSequential import PurgedKFold # the original code assume they are stored in different folder\u001B[39;00m\n\u001B[1;32m   1301\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cvGen \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# if there is no predetermined splits of the test sets and the training sets\u001B[39;00m\n\u001B[1;32m   1302\u001B[0m     \u001B[38;5;66;03m# use the PurgedKFold to generate splits of the test sets and the training sets\u001B[39;00m\n\u001B[0;32m-> 1303\u001B[0m     cvGen \u001B[38;5;241m=\u001B[39m \u001B[43mPurgedKFold\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_splits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpctEmbargo\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpctEmbargo\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# purged\u001B[39;00m\n\u001B[1;32m   1304\u001B[0m score \u001B[38;5;241m=\u001B[39m []  \u001B[38;5;66;03m# store the CV scores\u001B[39;00m\n\u001B[1;32m   1305\u001B[0m \u001B[38;5;66;03m# for each fold\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/Pycharm/Financial_Machine_Learning/FinancialMachineLearning.py:1246\u001B[0m, in \u001B[0;36mPurgedKFold.__init__\u001B[0;34m(self, n_splits, t1, pctEmbargo)\u001B[0m\n\u001B[1;32m   1243\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, n_splits\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, t1\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, pctEmbargo\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.\u001B[39m):\n\u001B[1;32m   1244\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t1, pd\u001B[38;5;241m.\u001B[39mSeries):\n\u001B[1;32m   1245\u001B[0m         \u001B[38;5;66;03m# if t1 is not a pd.series, raise error\u001B[39;00m\n\u001B[0;32m-> 1246\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLabel Through Dates must be a pd.Series\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   1247\u001B[0m     \u001B[38;5;66;03m# inherit _BaseKFold, no shuffle\u001B[39;00m\n\u001B[1;32m   1248\u001B[0m     \u001B[38;5;66;03m# Might be python 2x style\u001B[39;00m\n\u001B[1;32m   1249\u001B[0m     \u001B[38;5;28msuper\u001B[39m(PurgedKFold, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(n_splits, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[0;31mValueError\u001B[0m: Label Through Dates must be a pd.Series"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 1000, criterion = \"entropy\", bootstrap = True,\n",
    "                                n_jobs = 1, random_state = 42, class_weight = 'balanced_subsample', oob_score = False)\n",
    "score = fml.cvScore(rf, X, y, sample_weight = cweight, scoring = 'neg_log_loss', cv = 10, pctEmbargo = 0)\n",
    "print('rf_clf Mean CV score: {0:.6f}\\nCV Variance: {1:.6f}'.format(score.mean(), score.var()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
