{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import FinancialMachineLearning as fml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T16:56:44.043654Z",
     "start_time": "2023-05-12T16:56:41.300719Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.96\n",
      "[36.17 36.25 36.21 ... 29.26 29.26 29.26]\n",
      "[1.41225268 1.41537627 1.41381447 ... 1.14245268 1.14245268 1.14245268]\n"
     ]
    },
    {
     "data": {
      "text/plain": "                      price     bid     ask   size      v          dv\ndates                                                                \n2009-09-28 09:30:00   50.79   50.70   50.79    100    100     5079.00\n2009-09-28 09:30:00   50.71   50.70   50.79    638    638    32352.98\n2009-09-28 09:31:32   50.75   50.75   50.76    100    100     5075.00\n2009-09-28 09:31:33   50.75   50.72   50.75    100    100     5075.00\n2009-09-28 09:31:50   50.75   50.73   50.76    300    300    15225.00\n...                     ...     ...     ...    ...    ...         ...\n2018-10-05 15:59:59  116.20  116.18  116.19   2000   2000   232400.00\n2018-10-05 15:59:59  116.20  116.18  116.19   3900   3900   453180.00\n2018-10-05 16:00:00  116.22  116.20  116.21  42884  42884  4983978.48\n2018-10-05 16:10:00  116.22    0.00  117.10      0      0        0.00\n2018-10-05 18:30:00  116.22  114.71  117.95      0      0        0.00\n\n[1416200 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>bid</th>\n      <th>ask</th>\n      <th>size</th>\n      <th>v</th>\n      <th>dv</th>\n    </tr>\n    <tr>\n      <th>dates</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2009-09-28 09:30:00</th>\n      <td>50.79</td>\n      <td>50.70</td>\n      <td>50.79</td>\n      <td>100</td>\n      <td>100</td>\n      <td>5079.00</td>\n    </tr>\n    <tr>\n      <th>2009-09-28 09:30:00</th>\n      <td>50.71</td>\n      <td>50.70</td>\n      <td>50.79</td>\n      <td>638</td>\n      <td>638</td>\n      <td>32352.98</td>\n    </tr>\n    <tr>\n      <th>2009-09-28 09:31:32</th>\n      <td>50.75</td>\n      <td>50.75</td>\n      <td>50.76</td>\n      <td>100</td>\n      <td>100</td>\n      <td>5075.00</td>\n    </tr>\n    <tr>\n      <th>2009-09-28 09:31:33</th>\n      <td>50.75</td>\n      <td>50.72</td>\n      <td>50.75</td>\n      <td>100</td>\n      <td>100</td>\n      <td>5075.00</td>\n    </tr>\n    <tr>\n      <th>2009-09-28 09:31:50</th>\n      <td>50.75</td>\n      <td>50.73</td>\n      <td>50.76</td>\n      <td>300</td>\n      <td>300</td>\n      <td>15225.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2018-10-05 15:59:59</th>\n      <td>116.20</td>\n      <td>116.18</td>\n      <td>116.19</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>232400.00</td>\n    </tr>\n    <tr>\n      <th>2018-10-05 15:59:59</th>\n      <td>116.20</td>\n      <td>116.18</td>\n      <td>116.19</td>\n      <td>3900</td>\n      <td>3900</td>\n      <td>453180.00</td>\n    </tr>\n    <tr>\n      <th>2018-10-05 16:00:00</th>\n      <td>116.22</td>\n      <td>116.20</td>\n      <td>116.21</td>\n      <td>42884</td>\n      <td>42884</td>\n      <td>4983978.48</td>\n    </tr>\n    <tr>\n      <th>2018-10-05 16:10:00</th>\n      <td>116.22</td>\n      <td>0.00</td>\n      <td>117.10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>2018-10-05 18:30:00</th>\n      <td>116.22</td>\n      <td>114.71</td>\n      <td>117.95</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>1416200 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('./Data/IVE_tickbidask.parq')\n",
    "mad = fml.madOutlier(df.price.values.reshape(-1, 1))\n",
    "df = df.loc[~mad]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T17:00:51.214912Z",
     "start_time": "2023-05-12T17:00:49.012073Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chapter 7. Cross-Validation in Finance\n",
    "\n",
    "#### Exercise 1\n",
    "\n",
    "금융에 있어서 K-Fold Cross Validation을 수행하기 전에 데이터셋을 섞는 것이 일반적으로 좋지 않은 이유는 무엇인가?데이터를 Shuffling하는 목적은 무엇인가? 데이터를 Shuffling하면 금융 데이터셋에 있어 K-Fold Cross Validation의 목적이 무의미해지는 이유는 무엇인가?\n",
    "\n",
    "답 : 우리가 사용하는 금융 시계열 데이터셋인데, 만약 데이터셋을 섞게 된다면 순차적 시간 정보다 뒤섞이게 된다. 이는 오히려 추정기의 성능을 떨어뜨리는 결과를 낳게 된다. 일반적으로 Data Science 분야에서 교차 검증을 위해 데이터를 섞는 이유는 무작위 표본 추출로 test, validation, train set을 선택하기 위함인데, 금융 시계열 데이터에서는 Shuffling을 한다면 시간 정보가 사라지고, information leak 등의 다양한 문제가 발생하게 되어 결과적으로 목적이 무의미해진다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 2\n",
    "\n",
    "관측된 특성과 레이블로 구성된 한 쌍의 행렬$(X,y)$을 하나 구하자. 3장 연습 문제에서 도출한 데이터셋 중 하나를 사용해도 된다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-12T16:56:44.105126Z",
     "start_time": "2023-05-12T16:56:44.035879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               Unnamed: 0    dollar  frac_diff_dollar        tW         w  bin\n0     2009-11-04 14:41:43   50.4500          0.529761  0.750000  1.984399 -1.0\n1     2009-11-04 15:43:57   49.8800         -0.137134  0.444444  0.077423  1.0\n2     2009-11-05 09:46:35   50.2080          0.349295  0.388889  3.523273  1.0\n3     2009-11-06 10:39:27   50.5448          0.038635  0.333333  3.626638  1.0\n4     2009-11-06 12:37:18   50.9232          0.559177  0.333333  2.644159  1.0\n...                   ...       ...               ...       ...       ...  ...\n3467  2018-09-26 10:07:41  116.5780          0.334817  0.209694  0.813016 -1.0\n3468  2018-09-26 15:47:29  115.9960          0.220088  0.189087  0.495700  1.0\n3469  2018-09-27 10:02:15  116.1100          0.750801  0.176905  0.055908 -1.0\n3470  2018-09-27 15:39:35  115.9000          0.349971  0.166905  0.621259  1.0\n3471  2018-09-28 10:35:39  115.9530          0.746292  0.166905  0.122451  1.0\n\n[3472 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>dollar</th>\n      <th>frac_diff_dollar</th>\n      <th>tW</th>\n      <th>w</th>\n      <th>bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2009-11-04 14:41:43</td>\n      <td>50.4500</td>\n      <td>0.529761</td>\n      <td>0.750000</td>\n      <td>1.984399</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2009-11-04 15:43:57</td>\n      <td>49.8800</td>\n      <td>-0.137134</td>\n      <td>0.444444</td>\n      <td>0.077423</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2009-11-05 09:46:35</td>\n      <td>50.2080</td>\n      <td>0.349295</td>\n      <td>0.388889</td>\n      <td>3.523273</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009-11-06 10:39:27</td>\n      <td>50.5448</td>\n      <td>0.038635</td>\n      <td>0.333333</td>\n      <td>3.626638</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009-11-06 12:37:18</td>\n      <td>50.9232</td>\n      <td>0.559177</td>\n      <td>0.333333</td>\n      <td>2.644159</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3467</th>\n      <td>2018-09-26 10:07:41</td>\n      <td>116.5780</td>\n      <td>0.334817</td>\n      <td>0.209694</td>\n      <td>0.813016</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>3468</th>\n      <td>2018-09-26 15:47:29</td>\n      <td>115.9960</td>\n      <td>0.220088</td>\n      <td>0.189087</td>\n      <td>0.495700</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3469</th>\n      <td>2018-09-27 10:02:15</td>\n      <td>116.1100</td>\n      <td>0.750801</td>\n      <td>0.176905</td>\n      <td>0.055908</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>3470</th>\n      <td>2018-09-27 15:39:35</td>\n      <td>115.9000</td>\n      <td>0.349971</td>\n      <td>0.166905</td>\n      <td>0.621259</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3471</th>\n      <td>2018-09-28 10:35:39</td>\n      <td>115.9530</td>\n      <td>0.746292</td>\n      <td>0.166905</td>\n      <td>0.122451</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3472 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sp500featureBin.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1].values # dollar, frac_diff, tW, w\n",
    "y = df.iloc[:,-1].values.reshape(-1,1) # bin"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T16:56:44.105496Z",
     "start_time": "2023-05-12T16:56:44.094268Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, BaggingClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle = False, random_state = 42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T16:56:44.105587Z",
     "start_time": "2023-05-12T16:56:44.094866Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(a)** $(X,y)$에 대해 데이터를 Shuffling하지 않고 Random Forest Classifier의 10 Fold Cross Validation의 성능을 도출해 보라"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "classes = np.unique(y_train.reshape(1,-1))\n",
    "weights = compute_class_weight(class_weight = 'balanced', classes = classes, y = y_train.reshape(-1,))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T16:56:44.105671Z",
     "start_time": "2023-05-12T16:56:44.094988Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "      class_weight\n0         0.888158\n1         1.144068\n2         1.144068\n3         1.144068\n4         1.144068\n...            ...\n3467      0.888158\n3468      1.144068\n3469      0.888158\n3470      1.144068\n3471      1.144068\n\n[3472 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class_weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.888158</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.144068</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.144068</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.144068</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.144068</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3467</th>\n      <td>0.888158</td>\n    </tr>\n    <tr>\n      <th>3468</th>\n      <td>1.144068</td>\n    </tr>\n    <tr>\n      <th>3469</th>\n      <td>0.888158</td>\n    </tr>\n    <tr>\n      <th>3470</th>\n      <td>1.144068</td>\n    </tr>\n    <tr>\n      <th>3471</th>\n      <td>1.144068</td>\n    </tr>\n  </tbody>\n</table>\n<p>3472 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cweight = pd.DataFrame()\n",
    "cweight.index = df.index\n",
    "cweight['class_weight'] = np.nan\n",
    "cweight.loc[df[df.bin == -1.0].index] = weights[1]\n",
    "cweight.loc[df[df.bin == 1.0].index] = weights[0]\n",
    "cweight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T16:56:44.118034Z",
     "start_time": "2023-05-12T16:56:44.107061Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_clf Mean CV score: -0.717943\n",
      "CV Variance: 0.006818\n"
     ]
    }
   ],
   "source": [
    "#based on book recommendation\n",
    "rf = RandomForestClassifier(n_estimators = 1000, criterion = \"entropy\", bootstrap = True,\n",
    "                                n_jobs=1, random_state=42, class_weight = 'balanced_subsample', oob_score=False)\n",
    "cv_gen = KFold(n_splits = 10, shuffle = False)\n",
    "score = fml.cvScore(rf, X, y, sample_weight = cweight, scoring = 'neg_log_loss', cv = None, cvGen = cv_gen, pctEmbargo = 0)\n",
    "print('rf_clf Mean CV score: {0:.6f}\\nCV Variance: {1:.6f}'.format(score.mean(), score.var()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T16:58:03.320344Z",
     "start_time": "2023-05-12T16:56:44.118564Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(b)** $(X,y)$에 대해 데이터를 섞으며 Random Forest Classifier의 10 Fold Cross Validation의 검증 성능을 도출해 보라"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_clf Mean CV score: -0.556278\n",
      "CV Variance: 0.000234\n"
     ]
    }
   ],
   "source": [
    "cv_gen0 = KFold(n_splits = 10, random_state = 42, shuffle = True)\n",
    "\n",
    "score = fml.cvScore(rf, X, y, sample_weight = cweight, scoring = 'neg_log_loss', cv = None, cvGen = cv_gen0, pctEmbargo = 0)\n",
    "print('rf_clf Mean CV score: {0:.6f}\\nCV Variance: {1:.6f}'.format(score.mean(), score.var()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T16:59:22.951081Z",
     "start_time": "2023-05-12T16:58:03.322111Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(c)** 두 결과가 많이 다른 이유는 무엇인가?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(d)** 데이터를 Shuffling하면 Information Leak이 어떻게 일어나는가?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 3\n",
    "Exercise 2에서 사용한 것과 동일한 $(X,y)$행렬을 사용하자\n",
    "\n",
    "**(a)** $(X,y)$에 대해 1% Embargo를 사용한 Random Forest Classifier의 10 Fold Purged Cross Validation의 검증 성능을 도출해 보라"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                      price     bid     ask   size      v          dv\ndates                                                                \n2009-09-28 09:46:35   51.07   51.05   51.07    900    900    45963.00\n2009-09-28 09:53:49   51.14   51.13   51.14   2000   2000   102280.00\n2009-09-28 09:55:26   51.14   51.11   51.14    100    100     5114.00\n2009-09-28 10:02:52   51.25   51.24   51.26   4300   4300   220375.00\n2009-09-28 10:10:21   51.29   51.28   51.29   4500   4500   230805.00\n...                     ...     ...     ...    ...    ...         ...\n2018-10-05 15:58:23  116.19  116.19  116.20   1354   1354   157321.26\n2018-10-05 15:59:20  116.18  116.17  116.19    300    300    34854.00\n2018-10-05 15:59:55  116.19  116.18  116.20    800    800    92952.00\n2018-10-05 15:59:59  116.20  116.18  116.19   2000   2000   232400.00\n2018-10-05 16:00:00  116.22  116.20  116.21  42884  42884  4983978.48\n\n[49996 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>bid</th>\n      <th>ask</th>\n      <th>size</th>\n      <th>v</th>\n      <th>dv</th>\n    </tr>\n    <tr>\n      <th>dates</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2009-09-28 09:46:35</th>\n      <td>51.07</td>\n      <td>51.05</td>\n      <td>51.07</td>\n      <td>900</td>\n      <td>900</td>\n      <td>45963.00</td>\n    </tr>\n    <tr>\n      <th>2009-09-28 09:53:49</th>\n      <td>51.14</td>\n      <td>51.13</td>\n      <td>51.14</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>102280.00</td>\n    </tr>\n    <tr>\n      <th>2009-09-28 09:55:26</th>\n      <td>51.14</td>\n      <td>51.11</td>\n      <td>51.14</td>\n      <td>100</td>\n      <td>100</td>\n      <td>5114.00</td>\n    </tr>\n    <tr>\n      <th>2009-09-28 10:02:52</th>\n      <td>51.25</td>\n      <td>51.24</td>\n      <td>51.26</td>\n      <td>4300</td>\n      <td>4300</td>\n      <td>220375.00</td>\n    </tr>\n    <tr>\n      <th>2009-09-28 10:10:21</th>\n      <td>51.29</td>\n      <td>51.28</td>\n      <td>51.29</td>\n      <td>4500</td>\n      <td>4500</td>\n      <td>230805.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2018-10-05 15:58:23</th>\n      <td>116.19</td>\n      <td>116.19</td>\n      <td>116.20</td>\n      <td>1354</td>\n      <td>1354</td>\n      <td>157321.26</td>\n    </tr>\n    <tr>\n      <th>2018-10-05 15:59:20</th>\n      <td>116.18</td>\n      <td>116.17</td>\n      <td>116.19</td>\n      <td>300</td>\n      <td>300</td>\n      <td>34854.00</td>\n    </tr>\n    <tr>\n      <th>2018-10-05 15:59:55</th>\n      <td>116.19</td>\n      <td>116.18</td>\n      <td>116.20</td>\n      <td>800</td>\n      <td>800</td>\n      <td>92952.00</td>\n    </tr>\n    <tr>\n      <th>2018-10-05 15:59:59</th>\n      <td>116.20</td>\n      <td>116.18</td>\n      <td>116.19</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>232400.00</td>\n    </tr>\n    <tr>\n      <th>2018-10-05 16:00:00</th>\n      <td>116.22</td>\n      <td>116.20</td>\n      <td>116.21</td>\n      <td>42884</td>\n      <td>42884</td>\n      <td>4983978.48</td>\n    </tr>\n  </tbody>\n</table>\n<p>49996 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dollar_M = 1000000\n",
    "dollar_df = fml.BarSampling(df, 'dv', dollar_M)\n",
    "dollar_df = dollar_df.groupby(level = 0).first()\n",
    "dollar_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T17:01:17.403408Z",
     "start_time": "2023-05-12T17:01:17.029331Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Label Through Dates must be a pd.Series",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/_x/jd8cnzcs4v9dgfmy2l73m8b80000gn/T/ipykernel_51200/1112415679.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m rf = RandomForestClassifier(n_estimators = 1000, criterion = \"entropy\", bootstrap = True,\n\u001B[1;32m      2\u001B[0m                                 n_jobs = 1, random_state = 42, class_weight = 'balanced_subsample', oob_score = False)\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mscore\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcvScore\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscoring\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'neg_log_loss'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpctEmbargo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'rf_clf Mean CV score: {0:.6f}\\nCV Variance: {1:.6f}'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mscore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/Pycharm/Financial_Machine_Learning/FinancialMachineLearning.py\u001B[0m in \u001B[0;36mcvScore\u001B[0;34m(clf, X, y, sample_weight, scoring, t1, cv, cvGen, pctEmbargo)\u001B[0m\n\u001B[1;32m   1301\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mcvGen\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# if there is no predetermined splits of the test sets and the training sets\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1302\u001B[0m         \u001B[0;31m# use the PurgedKFold to generate splits of the test sets and the training sets\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1303\u001B[0;31m         \u001B[0mcvGen\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPurgedKFold\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_splits\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt1\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mt1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpctEmbargo\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpctEmbargo\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# purged\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1304\u001B[0m     \u001B[0mscore\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m  \u001B[0;31m# store the CV scores\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1305\u001B[0m     \u001B[0;31m# for each fold\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/Pycharm/Financial_Machine_Learning/FinancialMachineLearning.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, n_splits, t1, pctEmbargo)\u001B[0m\n\u001B[1;32m   1244\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1245\u001B[0m             \u001B[0;31m# if t1 is not a pd.series, raise error\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1246\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Label Through Dates must be a pd.Series'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1247\u001B[0m         \u001B[0;31m# inherit _BaseKFold, no shuffle\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1248\u001B[0m         \u001B[0;31m# Might be python 2x style\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Label Through Dates must be a pd.Series"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 1000, criterion = \"entropy\", bootstrap = True,\n",
    "                                n_jobs = 1, random_state = 42, class_weight = 'balanced_subsample', oob_score = False)\n",
    "score = fml.cvScore(rf, X, y, sample_weight = cweight, scoring = 'neg_log_loss', cv = 10, pctEmbargo = 0)\n",
    "print('rf_clf Mean CV score: {0:.6f}\\nCV Variance: {1:.6f}'.format(score.mean(), score.var()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T16:59:23.386310Z",
     "start_time": "2023-05-12T16:59:22.978765Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-12T16:59:23.385790Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
