{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import FinancialMachineLearning as fml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T11:50:01.816929Z",
     "start_time": "2023-05-11T11:50:00.707551Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chapter 7. Cross-Validation in Finance\n",
    "\n",
    "#### Exercise 1\n",
    "\n",
    "금융에 있어서 K-Fold Cross Validation을 수행하기 전에 데이터셋을 섞는 것이 일반적으로 좋지 않은 이유는 무엇인가?데이터를 Shuffling하는 목적은 무엇인가? 데이터를 Shuffling하면 금융 데이터셋에 있어 K-Fold Cross Validation의 목적이 무의미해지는 이유는 무엇인가?\n",
    "\n",
    "답 : 우리가 사용하는 금융 시계열 데이터셋인데, 만약 데이터셋을 섞게 된다면 순차적 시간 정보다 뒤섞이게 된다. 이는 오히려 추정기의 성능을 떨어뜨리는 결과를 낳게 된다. 일반적으로 Data Science 분야에서 교차 검증을 위해 데이터를 섞는 이유는 무작위 표본 추출로 test, validation, train set을 선택하기 위함인데, 금융 시계열 데이터에서는 Shuffling을 한다면 시간 정보가 사라지고, information leak 등의 다양한 문제가 발생하게 되어 결과적으로 목적이 무의미해진다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 2\n",
    "\n",
    "관측된 특성과 레이블로 구성된 한 쌍의 행렬$(X,y)$을 하나 구하자. 3장 연습 문제에서 도출한 데이터셋 중 하나를 사용해도 된다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-11T11:50:01.835781Z",
     "start_time": "2023-05-11T11:50:01.817821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               Unnamed: 0    dollar  frac_diff_dollar        tW         w  bin\n0     2009-11-04 14:41:43   50.4500          0.529761  0.750000  1.984399 -1.0\n1     2009-11-04 15:43:57   49.8800         -0.137134  0.444444  0.077423  1.0\n2     2009-11-05 09:46:35   50.2080          0.349295  0.388889  3.523273  1.0\n3     2009-11-06 10:39:27   50.5448          0.038635  0.333333  3.626638  0.0\n4     2009-11-06 12:37:18   50.9232          0.559177  0.333333  2.644159  0.0\n...                   ...       ...               ...       ...       ...  ...\n3471  2018-09-26 10:07:41  116.5780          0.334817  0.209694  0.813016  0.0\n3472  2018-09-26 15:47:29  115.9960          0.220088  0.189087  0.495700  0.0\n3473  2018-09-27 10:02:15  116.1100          0.750801  0.176905  0.055908  0.0\n3474  2018-09-27 15:39:35  115.9000          0.349971  0.166905  0.621259  0.0\n3475  2018-09-28 10:35:39  115.9530          0.746292  0.166905  0.122451  0.0\n\n[3476 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>dollar</th>\n      <th>frac_diff_dollar</th>\n      <th>tW</th>\n      <th>w</th>\n      <th>bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2009-11-04 14:41:43</td>\n      <td>50.4500</td>\n      <td>0.529761</td>\n      <td>0.750000</td>\n      <td>1.984399</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2009-11-04 15:43:57</td>\n      <td>49.8800</td>\n      <td>-0.137134</td>\n      <td>0.444444</td>\n      <td>0.077423</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2009-11-05 09:46:35</td>\n      <td>50.2080</td>\n      <td>0.349295</td>\n      <td>0.388889</td>\n      <td>3.523273</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009-11-06 10:39:27</td>\n      <td>50.5448</td>\n      <td>0.038635</td>\n      <td>0.333333</td>\n      <td>3.626638</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009-11-06 12:37:18</td>\n      <td>50.9232</td>\n      <td>0.559177</td>\n      <td>0.333333</td>\n      <td>2.644159</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3471</th>\n      <td>2018-09-26 10:07:41</td>\n      <td>116.5780</td>\n      <td>0.334817</td>\n      <td>0.209694</td>\n      <td>0.813016</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3472</th>\n      <td>2018-09-26 15:47:29</td>\n      <td>115.9960</td>\n      <td>0.220088</td>\n      <td>0.189087</td>\n      <td>0.495700</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3473</th>\n      <td>2018-09-27 10:02:15</td>\n      <td>116.1100</td>\n      <td>0.750801</td>\n      <td>0.176905</td>\n      <td>0.055908</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3474</th>\n      <td>2018-09-27 15:39:35</td>\n      <td>115.9000</td>\n      <td>0.349971</td>\n      <td>0.166905</td>\n      <td>0.621259</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3475</th>\n      <td>2018-09-28 10:35:39</td>\n      <td>115.9530</td>\n      <td>0.746292</td>\n      <td>0.166905</td>\n      <td>0.122451</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3476 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sp500feature.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1].values # dollar, frac_diff, tW, w\n",
    "y = df.iloc[:,-1].values.reshape(-1,1) # bin"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T11:50:01.856616Z",
     "start_time": "2023-05-11T11:50:01.837614Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, BaggingClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle = False, random_state = 42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T11:50:01.857296Z",
     "start_time": "2023-05-11T11:50:01.842328Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(a)** $(X,y)$에 대해 데이터를 Shuffling하지 않고 Random Forest Classifier의 10 Fold Cross Validation의 성능을 도출해 보라"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "sample_weight.shape == (3,), expected (3128,)!",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/_x/jd8cnzcs4v9dgfmy2l73m8b80000gn/T/ipykernel_38973/4230904512.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m                                 n_jobs=1, random_state=42, class_weight = 'balanced_subsample', oob_score=False)\n\u001B[1;32m     10\u001B[0m \u001B[0mcv_gen\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mKFold\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_splits\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshuffle\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0mscore\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcvScore\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mweights\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscoring\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'neg_log_loss'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcvGen\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcv_gen\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpctEmbargo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'rf_clf Mean CV score: {0:.6f}\\nCV Variance: {1:.6f}'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mscore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/Pycharm/Financial_Machine_Learning/FinancialMachineLearning.py\u001B[0m in \u001B[0;36mcvScore\u001B[0;34m(clf, X, y, sample_weight, scoring, t1, cv, cvGen, pctEmbargo)\u001B[0m\n\u001B[1;32m   1306\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mcvGen\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1307\u001B[0m         \u001B[0;31m# fit the model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1308\u001B[0;31m         fit = clf.fit(X = pd.DataFrame(X).iloc[:,1:].iloc[train, :], y = pd.DataFrame(y).iloc[train],\n\u001B[0m\u001B[1;32m   1309\u001B[0m                       sample_weight = pd.DataFrame(sample_weight).values.reshape(1,-1)[0])\n\u001B[1;32m   1310\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mscoring\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'neg_log_loss'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    329\u001B[0m         )\n\u001B[1;32m    330\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0msample_weight\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 331\u001B[0;31m             \u001B[0msample_weight\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_check_sample_weight\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    332\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    333\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0missparse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36m_check_sample_weight\u001B[0;34m(sample_weight, X, dtype, copy)\u001B[0m\n\u001B[1;32m   1563\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1564\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mn_samples\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1565\u001B[0;31m             raise ValueError(\n\u001B[0m\u001B[1;32m   1566\u001B[0m                 \"sample_weight.shape == {}, expected {}!\".format(\n\u001B[1;32m   1567\u001B[0m                     \u001B[0msample_weight\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mn_samples\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: sample_weight.shape == (3,), expected (3128,)!"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "classes = np.unique(y_train.reshape(1,-1))\n",
    "weights = compute_class_weight(class_weight = 'balanced', classes = classes, y = y_train.reshape(-1,))\n",
    "#based on book recommendation\n",
    "rf = RandomForestClassifier(n_estimators = 1000, criterion = \"entropy\", bootstrap = True,\n",
    "                                n_jobs=1, random_state=42, class_weight = 'balanced_subsample', oob_score=False)\n",
    "cv_gen = KFold(n_splits = 10, shuffle = False)\n",
    "score = fml.cvScore(rf, X, y, sample_weight = weights, scoring = 'neg_log_loss', cv = None, cvGen = cv_gen, pctEmbargo = 0)\n",
    "print('rf_clf Mean CV score: {0:.6f}\\nCV Variance: {1:.6f}'.format(score.mean(), score.var()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T11:50:02.071053Z",
     "start_time": "2023-05-11T11:50:01.847801Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "               Unnamed: 0    dollar  frac_diff_dollar        tW         w  bin\n0     2009-11-04 14:41:43   50.4500          0.529761  0.750000  1.984399 -1.0\n7     2009-11-11 10:05:43   52.7001          0.592277  0.297222  0.557362 -1.0\n9     2009-11-11 12:43:09   52.5260          0.485345  0.237500  0.292546 -1.0\n50    2010-01-20 10:54:08   54.4900         -0.010613  0.256667  3.026698 -1.0\n51    2010-01-20 14:52:58   54.6478          0.446691  0.277778  1.421287 -1.0\n...                   ...       ...               ...       ...       ...  ...\n3326  2018-04-30 13:01:26  110.6100          0.733846  0.149752  2.022865 -1.0\n3397  2018-06-22 09:46:03  112.0600          0.763690  0.142526  0.426862 -1.0\n3398  2018-06-22 10:05:28  112.1400          0.790298  0.142460  1.025435 -1.0\n3399  2018-06-25 09:45:01  111.2300          0.351443  0.121854  1.266857 -1.0\n3469  2018-09-24 09:46:29  118.4200          0.538707  0.270833  2.079205 -1.0\n\n[279 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>dollar</th>\n      <th>frac_diff_dollar</th>\n      <th>tW</th>\n      <th>w</th>\n      <th>bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2009-11-04 14:41:43</td>\n      <td>50.4500</td>\n      <td>0.529761</td>\n      <td>0.750000</td>\n      <td>1.984399</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2009-11-11 10:05:43</td>\n      <td>52.7001</td>\n      <td>0.592277</td>\n      <td>0.297222</td>\n      <td>0.557362</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2009-11-11 12:43:09</td>\n      <td>52.5260</td>\n      <td>0.485345</td>\n      <td>0.237500</td>\n      <td>0.292546</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>2010-01-20 10:54:08</td>\n      <td>54.4900</td>\n      <td>-0.010613</td>\n      <td>0.256667</td>\n      <td>3.026698</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>2010-01-20 14:52:58</td>\n      <td>54.6478</td>\n      <td>0.446691</td>\n      <td>0.277778</td>\n      <td>1.421287</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3326</th>\n      <td>2018-04-30 13:01:26</td>\n      <td>110.6100</td>\n      <td>0.733846</td>\n      <td>0.149752</td>\n      <td>2.022865</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>3397</th>\n      <td>2018-06-22 09:46:03</td>\n      <td>112.0600</td>\n      <td>0.763690</td>\n      <td>0.142526</td>\n      <td>0.426862</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>3398</th>\n      <td>2018-06-22 10:05:28</td>\n      <td>112.1400</td>\n      <td>0.790298</td>\n      <td>0.142460</td>\n      <td>1.025435</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>3399</th>\n      <td>2018-06-25 09:45:01</td>\n      <td>111.2300</td>\n      <td>0.351443</td>\n      <td>0.121854</td>\n      <td>1.266857</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>3469</th>\n      <td>2018-09-24 09:46:29</td>\n      <td>118.4200</td>\n      <td>0.538707</td>\n      <td>0.270833</td>\n      <td>2.079205</td>\n      <td>-1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>279 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.bin == -1.0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T11:55:46.812470Z",
     "start_time": "2023-05-11T11:55:46.774816Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([4.18041237, 0.3827277 , 6.75833333])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T11:55:14.945628Z",
     "start_time": "2023-05-11T11:55:14.938476Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
